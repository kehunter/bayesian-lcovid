{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a7497b-e344-49e5-a03a-b9684b154be5",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84323182-098a-4151-ab8c-b4d82b0c0d38",
   "metadata": {},
   "source": [
    "## Imports and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe604829-fc48-42f9-8958-6066365be1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import RocCurveDisplay, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22782f40-90da-49f9-8c58-eb077d85da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8927\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7534ccb-9e42-47fe-806a-9476be635002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "zip_file = ZipFile(\"data/adult23csv.zip\")\n",
    "\n",
    "df_full = pd.read_csv(zip_file.open('adult23.csv'))\n",
    "y_name = 'LONGCOVD1_A'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5230d403-12b5-4090-b724-f8706e486923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess_all_columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_all_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78a7aa2-7ad7-4b8f-8af1-70067e185471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RATCAT_A_7.0', 'HISPALLP_A_7.0', 'RACEALLP_A_7.0', 'CITZNSTP_A_7.0',\n",
       "       'SPOUSEDUCP_A_7.0', 'MARSTAT_A_7.0', 'SPOUSWRK_A_7.0',\n",
       "       'PCNTADWFP1_A_7.0', 'PCNTADWKP1_A_7.0', 'EMPWRKFT1_A_7.0',\n",
       "       ...\n",
       "       'STREV_A_7.0', 'MIEV_A_7.0', 'ANGEV_A_7.0', 'CHDEV_A_7.0',\n",
       "       'CHLEV_A_7.0', 'HYPEV_A_7.0', 'LSATIS4_A_7.0', 'PHSTAT_A_7.0',\n",
       "       'AVAIL_A_7.0', 'INTV_MON_7.0'],\n",
       "      dtype='object', length=238)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## HOW TO GET 9.0 and 7.0 COLUMN NAMES:\n",
    "X_train.filter(regex='_9\\.0$').columns\n",
    "X_train.filter(regex='_7\\.0$').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b12fa3a-b562-4617-b73f-27d4ddfa27fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "            \\begin{array}{rcl}\n",
       "            \\text{sigma} &\\sim & \\operatorname{HalfNormal}(0,~10)\\\\\\text{tau} &\\sim & \\operatorname{HalfStudentT}(2,~f(\\text{sigma}))\\\\\\text{lam} &\\sim & \\operatorname{HalfStudentT}(4,~1)\\\\\\text{c2} &\\sim & \\operatorname{InverseGamma}(1,~1)\\\\\\text{z} &\\sim & \\operatorname{Normal}(0,~1)\\\\\\text{beta0} &\\sim & \\operatorname{Normal}(0,~100)\\\\\\text{beta} &\\sim & \\operatorname{Deterministic}(f(\\text{lam},~\\text{z},~\\text{c2},~\\text{tau}))\\\\\\text{y} &\\sim & \\operatorname{Bernoulli}(f(\\text{beta0},~\\text{lam},~\\text{z},~\\text{c2},~\\text{tau}))\n",
       "            \\end{array}\n",
       "            $$"
      ],
      "text/plain": [
       "sigma ~ HalfNormal(0, 10)\n",
       "  tau ~ HalfStudentT(2, f(sigma))\n",
       "  lam ~ HalfStudentT(4, 1)\n",
       "   c2 ~ InverseGamma(1, 1)\n",
       "    z ~ Normal(0, 1)\n",
       "beta0 ~ Normal(0, 100)\n",
       " beta ~ Deterministic(f(lam, z, c2, tau))\n",
       "    y ~ Bernoulli(f(beta0, lam, z, c2, tau))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, D = X_train.shape\n",
    "\n",
    "coords = {\"predictors\" : X_train.columns.values}\n",
    "\n",
    "# # IT IS INTRACTIBLE TO RUN IT THIS WAY\n",
    "# with pm.Model(coords=coords) as sparse_model:\n",
    "#     X = X_train.values\n",
    "#     lamda = pm.HalfCauchy('lambda', beta=1, dims=\"predictors\")\n",
    "#     tau = pm.HalfCauchy('tau', beta=1)\n",
    "#     sigma = pm.Deterministic('horseshoe', tau*tau*lamda*lamda)\n",
    "#     beta = pm.Normal('beta', mu=0, sigma=sigma, dims=\"predictors\")\n",
    "#     beta0 = pm.Normal('beta0', mu=0, sigma=10)\n",
    "#     mu = pm.math.invlogit(pm.math.dot(X, beta) + beta0)\n",
    "#     y = pm.Bernoulli('obs', p=mu, observed=y_train.values)\n",
    "# sparse_model\n",
    "\n",
    "\n",
    "## SPARSITY ENFORCING PRIOR: https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_overview.html\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "N, D = X_train.shape\n",
    "D0 = 10 # guess at the true number of predictors\n",
    "\n",
    "with pm.Model(coords={\"predictors\": X_train.columns.values}) as sparse_model:\n",
    "\n",
    "    x = X_train.values\n",
    "    \n",
    "    # Prior on error SD\n",
    "    sigma = pm.HalfNormal(\"sigma\", 10)\n",
    "\n",
    "    # Global shrinkage prior\n",
    "    tau = pm.HalfStudentT(\"tau\", 2, D0 / (D - D0) * sigma / np.sqrt(N))\n",
    "    # Local shrinkage prior\n",
    "    lam = pm.HalfStudentT(\"lam\", 4, dims=\"predictors\")\n",
    "    c2 = pm.InverseGamma(\"c2\", 1, 1)\n",
    "    z = pm.Normal(\"z\", 0.0, 1.0, dims=\"predictors\")\n",
    "    # Shrunken coefficients\n",
    "    betas = pm.Deterministic(\n",
    "        \"beta\", z * tau * lam * pt.sqrt(c2 / (c2 + tau**2 * lam**2)), dims=\"predictors\"\n",
    "    )\n",
    "    # No shrinkage on intercept\n",
    "    b0 = pm.Normal(\"beta0\", 0, 100)\n",
    "\n",
    "    # Model\n",
    "    logitp = b0 + pm.math.dot(x, betas)\n",
    "    theta = 1 / (1 + pm.math.exp(-logitp))\n",
    "    y = pm.Bernoulli('y', p=theta, observed=y_train.values)\n",
    "\n",
    "sparse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a15afd1e-87ef-4819-9f48-a76d6a2789a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, tau, lam, c2, z, beta0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d558e77b4f41e3aeee8d3f89f25215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run MCMC to get posterior distribution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sparse_model:\n\u001b[0;32m----> 3\u001b[0m     idata_sparse \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Active_projects/AM207_project/.venv/lib/python3.11/site-packages/pymc/sampling/mcmc.py:891\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    889\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_return\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_sampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midata_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Active_projects/AM207_project/.venv/lib/python3.11/site-packages/pymc/sampling/mcmc.py:924\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[0;32m--> 924\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m \u001b[43m_choose_chains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    926\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Active_projects/AM207_project/.venv/lib/python3.11/site-packages/pymc/backends/base.py:603\u001b[0m, in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m    601\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) \u001b[38;5;241m-\u001b[39m tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough samples to build a trace.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lengths)\n\u001b[1;32m    606\u001b[0m l_sort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)[idxs]\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "# run MCMC to get posterior distribution\n",
    "with sparse_model:\n",
    "    idata_sparse = pm.sample(1000, tune=1500, target_accept=0.9)\n",
    "    print(f'DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4301443-554c-42d0-9fe5-5a768f7f925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = az.summary(idata_sparse, var_names=[\"betas\"], hdi_prob=0.95)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57a463-0a70-4ecd-bfa3-6ac5a96da41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(idata_sparse, var_names=[\"betas\"], combined=True, hdi_prob=0.95, r_hat=False, rope=(0,0), textsize=8);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168d082-1971-4dbc-bbe1-7eca91b01046",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.001\n",
    "np.abs(summary['mean']).sort_values(ascending=False)[:20].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ac43b-833e-4d7b-9d3e-b22798128caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# extract top 20 features but drop duplicates\n",
    "important = np.abs(summary['mean']).sort_values(ascending=False)[:20].index.values\n",
    "important_feats = [re.search('\\[(.+)_\\d+\\.0\\]',idx).group(1) for idx in important]\n",
    "# # preserve order\n",
    "important_feats = list(dict.fromkeys(important_feats)) \n",
    "print(important_feats)\n",
    "\n",
    "pattern = '|'.join(important_feats)\n",
    "# # filter to keep only relevant features\n",
    "X_train_new = X_train.filter(regex=pattern)\n",
    "X_test_new = X_test.filter(regex=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf06431-e2f0-4723-9594-3be7f2123d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
